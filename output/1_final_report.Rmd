---
title: "Walk_aurant_ify"
author: "MercedeszLehoczky"
date: "2023-04-28"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

This project is the final capstone project for the University of Lucerne FS23 "Data Mining in R" course.
The purpose of this project was to gain insights into data mining methods and to create an original project using the freshly learned skills.


## Idea
The project is meant to be an idea for a "self-care" walk. 
The user would access their Spotify account, choose a playlist, and the project matches the length of their playlist to a restaurant in Lucerne. The starting point is always the University of Lucerne and the route is calculated via walking.

For this, Spotify API, Google Places API and Google Directions API are used.



## Initialisation

From the user end, the user needs to create a Spotify app on <https://developer.spotify.com/> and have their "Client ID" and "Client secret" ready.
Furthermore, their Spotify User ID will also be needed. This can be found in the application Home > Settings > Account > Username or on <https://open.spotify.com> Display name (upper right corner) > Account > Username.

For Google API, get an API key from <https://developers.google.com/maps/>. 

Kindly consult the documentations for more precise information.

The scripts ask for the keys password-style, however, it is recommended to create a "keys.csv" file in the "data" folder to store these keys for the shiny application. The format is the following:

api_id            | api_key

spotify_id        | xxx         #client ID

spotify_secret    | xxx         #client secret

spotify_user      | xxx         #user ID

google_id         | xxx         #Google API key



### The playlists

After setting up the credentials, the first script (**"01_Spotify_playlists.R"**) is ran and the first important output is the names of playlists scraped.

There are issues with the functions used here. In the package "spotifyr", there are multiple great tools, but the function "get_user_playlists" is limited to maximum 50 playlists. The playlists are usually displaved as latest addition to oldest and include saved playlists from others too.

The goal is to scrape the length of the playlists, saved in seconds. Another issue is, that not all playlists are available for getting their track list, and hence, the length of the tracks (and playlist). This could be because of the playlist not being public or being owned by someone else. This will produce 404 errors while running the script, but most playlist data should still be available. 

If the user cannot scrape their playlist info, then the user should create a new public playlist, (ideally under 60 min, but the script won't check this) and after rerunning the script, proceed to the *Get specific playlist info* section, where the user will be asked to type their playlist name in the pop-up window.

```{r eval=FALSE, include=FALSE}
print(tibble(my_plists$name, my_plists$playlist_length_sec))
```

### Restaurants

Next, the restaurants from Lucerne are scraped using the Google Places API (**"02_Places_API.R"**).

The issue here is that the API only lets us scrape 60 restaurants at a time. 
The other issue is that scraping places tagged as restaurants will also scrape other establishments, such as hotels, since usually there are many tags in the 'types' section (like hotels, bars, gyms, etc). 

```{r eval=FALSE, include=FALSE}
print(data.frame(places_df$place_name, places_df$place_address))
```

### Routes

Then, the walking routes to each location (restaurant) are scraped via Google Directions API (**"03_Directions_API.R"**). The same API key can be used for this and *script 02*. The list of endpoints are given from the scraped table created in *script 02*.

```{r eval=FALSE, include=FALSE}
print(route_info)
```

### Matching

Finally, in script **"04_time_match.R"**, the length of the chosen playlist is matched to the closest restaurant on foot. 

The user can now take their walk while listening to their favorite songs and top the exercise off with some delicious food at the endpoint.

## Shiny, further applications

The author has tried to create a Shiny application to display their work and make it user-friendly.
The idea was to:

* load the previously created csv file with the API and username information
* create a drop-down list with the playlist names
* this would trigger the matching, which should be shown as a text output
* a Google Maps widget would show up at the Main section, that shows the route on foot to the restaurant (calculating in the server part of the Shiny app)
* at a playlist change, a new calculation would happen.

## Limitations
The main issues have been mentioned already at the relevant sections.

The Shiny application backend is almost complete, but the author couldn't figure out how to make the reactive functions work.

## Personal takeaway
The project was a good challenge to practice scraping and working with APIs, reading documentations. The author has also used GPT-3.5 for clarifications and code snippets, which was also a new type of application of knowledge for them.


Shiny applications are extremely handy and versatile, but the more steps are to be displayed with dynamic buttons and inputs, the task gets significantly complicated and it is relatively hard to debug.

